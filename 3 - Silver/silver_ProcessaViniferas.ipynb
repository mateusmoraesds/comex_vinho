{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "299e0c95-1968-4047-b356-04a1e0b06c62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Silver: Processamento Viniferas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03985f5c-e306-45b0-979e-a560ba7baeb9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importa√ß√£o de bibliotecas e fun√ß√µes padr√£o"
    }
   },
   "outputs": [],
   "source": [
    "%run \"../1 - Setup/Ingestao_bibliotecas_padrao\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ea4b60d-6823-42e8-986a-605e1dd46d22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f797643a-d19b-4264-865b-be6169e83b35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from vitivinicultura.bronze_processamento.processaviniferas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75bb4ca4-5813-470a-b3db-60a6595eb13f",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"ingestao_ts\":248},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762114856267}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Carregando arquivo csv da landing zone"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_original = spark.table(\"vitivinicultura.bronze_processamento.processaviniferas\").toPandas()\n",
    "\n",
    "# 2Ô∏è‚É£ Define a coluna com os dados separados por \";\"\n",
    "coluna = \"_c0\"\n",
    "\n",
    "# 3Ô∏è‚É£ Colunas adicionais\n",
    "colunas_adicionais = [\"ingestao_ts\", \"usuario_ingestao\"]\n",
    "df_extra = df_original[colunas_adicionais].copy()\n",
    "\n",
    "# 4Ô∏è‚É£ Quebra a string em colunas separadas\n",
    "linhas = df_original[coluna].str.split(';', expand=True)\n",
    "\n",
    "# 5Ô∏è‚É£ Garante que a primeira linha seja uma lista de strings v√°lida\n",
    "cabecalho = linhas.iloc[0].astype(str).fillna(\"coluna_sem_nome\").tolist()\n",
    "\n",
    "# 6Ô∏è‚É£ Define os nomes das colunas\n",
    "linhas.columns = cabecalho\n",
    "\n",
    "# 7Ô∏è‚É£ Remove a primeira linha (que era o cabe√ßalho original)\n",
    "df_original = spark.table(\"vitivinicultura.bronze_processamento.processaviniferas\").toPandas()\n",
    "\n",
    "# 2Ô∏è‚É£ Define a coluna com os dados separados por \";\"\n",
    "coluna = \"_c0\"\n",
    "\n",
    "# 3Ô∏è‚É£ Colunas adicionais\n",
    "colunas_adicionais = [\"ingestao_ts\", \"usuario_ingestao\"]\n",
    "df_extra = df_original[colunas_adicionais].copy()\n",
    "\n",
    "# 4Ô∏è‚É£ Quebra a string em colunas separadas\n",
    "linhas = df_original[coluna].str.split(';', expand=True)\n",
    "\n",
    "# 5Ô∏è‚É£ Garante que a primeira linha seja uma lista de strings v√°lida\n",
    "cabecalho = linhas.iloc[0].astype(str).fillna(\"coluna_sem_nome\").tolist()\n",
    "\n",
    "# 6Ô∏è‚É£ Define os nomes das colunas\n",
    "linhas.columns = cabecalho\n",
    "\n",
    "# 7Ô∏è‚É£ Remove a primeira linha (que era o cabe√ßalho original)\n",
    "df_tratado = linhas.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# 8Ô∏è‚É£ Corrige nomes vazios e duplicados\n",
    "df_tratado.columns = [\n",
    "    f\"{c}_{i}\" if list(linhas.columns).count(c) > 1 else c\n",
    "    for i, c in enumerate(linhas.columns)\n",
    "]\n",
    "\n",
    "# 8Ô∏è‚É£ Colunas que N√ÉO devem ser somadas e DEVEM permanecer como texto\n",
    "nao_somar = [\"id\", \"control\",\"cultivar\"]\n",
    "\n",
    "# 9Ô∏è‚É£ For√ßa as colunas de nao_somar para string\n",
    "for c in df_tratado.columns:\n",
    "    if any(c.startswith(ex) for ex in nao_somar):\n",
    "        df_tratado[c] = df_tratado[c].astype(str).fillna(\"\")\n",
    "    else:\n",
    "        # Converte as demais colunas para n√∫mero se poss√≠vel\n",
    "        df_tratado[c] = pd.to_numeric(df_tratado[c], errors=\"coerce\")\n",
    "\n",
    "# üîü Separa colunas num√©ricas e texto\n",
    "colunas_texto = [c for c in df_tratado.columns if any(c.startswith(ex) for ex in nao_somar)]\n",
    "colunas_numericas = [c for c in df_tratado.columns if c not in colunas_texto]\n",
    "\n",
    "# 11Ô∏è‚É£ Soma apenas colunas num√©ricas com nomes duplicados\n",
    "df_num = df_tratado[colunas_numericas].groupby(lambda x: x.split(\"_\")[0], axis=1).sum(min_count=1)\n",
    "\n",
    "# 12Ô∏è‚É£ Garante que texto n√£o seja afetado por agrupamento\n",
    "df_texto = df_tratado[colunas_texto].copy()\n",
    "\n",
    "# 13Ô∏è‚É£ Junta novamente texto e num√©ricos\n",
    "df_tratado_final = pd.concat([df_texto, df_num], axis=1)\n",
    "\n",
    "# 14Ô∏è‚É£ Junta as colunas adicionais\n",
    "df_final = pd.concat([df_extra.reset_index(drop=True), df_tratado_final], axis=1)\n",
    "df = df_final[df_final[\"id\"].notnull()]\n",
    "\n",
    "# üîπ Visualiza o resultado\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6989321-42fd-43ec-aaff-9e73c584d811",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " #Cria tabela gerenciada no Unity Catalog\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS vitivinicultura.silver_processamento.processaviniferas\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "df_spark = spark.createDataFrame(df_final)\n",
    "# Escrita no formato Delta Lake\n",
    "df_spark.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"vitivinicultura.silver_processamento.processaviniferas\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7966251320707165,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_ProcessaViniferas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
